{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f6aa451b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "from scipy.stats import chi2_contingency\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_recall_fscore_support\n",
    "import warnings\n",
    "import os\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# Load the dataset\n",
    "a1 = pd.read_excel(\"data/case_study1.xlsx\")\n",
    "a2 = pd.read_excel(\"data/case_study2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fead13d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = a1.copy()\n",
    "df2 = a2.copy()\n",
    "\n",
    "# Remove nulls\n",
    "df1 = df1.loc[df1['Age_Oldest_TL'] != -99999]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a26c46ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROSPECTID</th>\n",
       "      <th>Total_TL</th>\n",
       "      <th>Tot_Closed_TL</th>\n",
       "      <th>Tot_Active_TL</th>\n",
       "      <th>Total_TL_opened_L6M</th>\n",
       "      <th>Tot_TL_closed_L6M</th>\n",
       "      <th>pct_tl_open_L6M</th>\n",
       "      <th>pct_tl_closed_L6M</th>\n",
       "      <th>pct_active_tl</th>\n",
       "      <th>pct_closed_tl</th>\n",
       "      <th>...</th>\n",
       "      <th>CC_TL</th>\n",
       "      <th>Consumer_TL</th>\n",
       "      <th>Gold_TL</th>\n",
       "      <th>Home_TL</th>\n",
       "      <th>PL_TL</th>\n",
       "      <th>Secured_TL</th>\n",
       "      <th>Unsecured_TL</th>\n",
       "      <th>Other_TL</th>\n",
       "      <th>Age_Oldest_TL</th>\n",
       "      <th>Age_Newest_TL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.667</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROSPECTID  Total_TL  Tot_Closed_TL  Tot_Active_TL  Total_TL_opened_L6M  \\\n",
       "0           1         5              4              1                    0   \n",
       "1           2         1              0              1                    0   \n",
       "2           3         8              0              8                    1   \n",
       "3           4         1              0              1                    1   \n",
       "4           5         3              2              1                    0   \n",
       "\n",
       "   Tot_TL_closed_L6M  pct_tl_open_L6M  pct_tl_closed_L6M  pct_active_tl  \\\n",
       "0                  0            0.000                0.0          0.200   \n",
       "1                  0            0.000                0.0          1.000   \n",
       "2                  0            0.125                0.0          1.000   \n",
       "3                  0            1.000                0.0          1.000   \n",
       "4                  0            0.000                0.0          0.333   \n",
       "\n",
       "   pct_closed_tl  ...  CC_TL  Consumer_TL  Gold_TL  Home_TL  PL_TL  \\\n",
       "0          0.800  ...      0            0        1        0      4   \n",
       "1          0.000  ...      0            1        0        0      0   \n",
       "2          0.000  ...      0            6        1        0      0   \n",
       "3          0.000  ...      0            0        0        0      0   \n",
       "4          0.667  ...      0            0        0        0      0   \n",
       "\n",
       "   Secured_TL  Unsecured_TL  Other_TL  Age_Oldest_TL  Age_Newest_TL  \n",
       "0           1             4         0             72             18  \n",
       "1           0             1         0              7              7  \n",
       "2           2             6         0             47              2  \n",
       "3           0             1         1              5              5  \n",
       "4           3             0         2            131             32  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60479f0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PROSPECTID</th>\n",
       "      <th>time_since_recent_payment</th>\n",
       "      <th>time_since_first_deliquency</th>\n",
       "      <th>time_since_recent_deliquency</th>\n",
       "      <th>num_times_delinquent</th>\n",
       "      <th>max_delinquency_level</th>\n",
       "      <th>max_recent_level_of_deliq</th>\n",
       "      <th>num_deliq_6mts</th>\n",
       "      <th>num_deliq_12mts</th>\n",
       "      <th>num_deliq_6_12mts</th>\n",
       "      <th>...</th>\n",
       "      <th>pct_CC_enq_L6m_of_L12m</th>\n",
       "      <th>pct_PL_enq_L6m_of_ever</th>\n",
       "      <th>pct_CC_enq_L6m_of_ever</th>\n",
       "      <th>max_unsec_exposure_inPct</th>\n",
       "      <th>HL_Flag</th>\n",
       "      <th>GL_Flag</th>\n",
       "      <th>last_prod_enq2</th>\n",
       "      <th>first_prod_enq2</th>\n",
       "      <th>Credit_Score</th>\n",
       "      <th>Approved_Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "      <td>35</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PL</td>\n",
       "      <td>PL</td>\n",
       "      <td>696</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>685</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>302</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5741.667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>ConsumerLoan</td>\n",
       "      <td>others</td>\n",
       "      <td>693</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.900</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>others</td>\n",
       "      <td>others</td>\n",
       "      <td>673</td>\n",
       "      <td>P2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>583</td>\n",
       "      <td>-99999</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>-99999</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99999.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>AL</td>\n",
       "      <td>AL</td>\n",
       "      <td>753</td>\n",
       "      <td>P1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PROSPECTID  time_since_recent_payment  time_since_first_deliquency  \\\n",
       "0           1                        549                           35   \n",
       "1           2                         47                       -99999   \n",
       "2           3                        302                           11   \n",
       "3           4                     -99999                       -99999   \n",
       "4           5                        583                       -99999   \n",
       "\n",
       "   time_since_recent_deliquency  num_times_delinquent  max_delinquency_level  \\\n",
       "0                            15                    11                     29   \n",
       "1                        -99999                     0                 -99999   \n",
       "2                             3                     9                     25   \n",
       "3                        -99999                     0                 -99999   \n",
       "4                        -99999                     0                 -99999   \n",
       "\n",
       "   max_recent_level_of_deliq  num_deliq_6mts  num_deliq_12mts  \\\n",
       "0                         29               0                0   \n",
       "1                          0               0                0   \n",
       "2                         25               1                9   \n",
       "3                          0               0                0   \n",
       "4                          0               0                0   \n",
       "\n",
       "   num_deliq_6_12mts  ...  pct_CC_enq_L6m_of_L12m  pct_PL_enq_L6m_of_ever  \\\n",
       "0                  0  ...                     0.0                     0.0   \n",
       "1                  0  ...                     0.0                     0.0   \n",
       "2                  8  ...                     0.0                     0.0   \n",
       "3                  0  ...                     0.0                     0.0   \n",
       "4                  0  ...                     0.0                     0.0   \n",
       "\n",
       "   pct_CC_enq_L6m_of_ever  max_unsec_exposure_inPct  HL_Flag  GL_Flag  \\\n",
       "0                     0.0                    13.333        1        0   \n",
       "1                     0.0                     0.860        0        0   \n",
       "2                     0.0                  5741.667        1        0   \n",
       "3                     0.0                     9.900        0        0   \n",
       "4                     0.0                -99999.000        0        0   \n",
       "\n",
       "   last_prod_enq2  first_prod_enq2  Credit_Score  Approved_Flag  \n",
       "0              PL               PL           696             P2  \n",
       "1    ConsumerLoan     ConsumerLoan           685             P2  \n",
       "2    ConsumerLoan           others           693             P2  \n",
       "3          others           others           673             P2  \n",
       "4              AL               AL           753             P1  \n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ea0e0cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51336, 62)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183d3360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROSPECTID\n"
     ]
    }
   ],
   "source": [
    "columns_to_be_removed = []\n",
    "\n",
    "for i in df2.columns:\n",
    "    if df2.loc[df2[i] == -99999].shape[0] > 10000:\n",
    "        columns_to_be_removed .append(i)\n",
    "\n",
    "df2 = df2.drop(columns_to_be_removed, axis =1)\n",
    "\n",
    "\n",
    "\n",
    "for i in df2.columns:\n",
    "    df2 = df2.loc[ df2[i] != -99999 ]\n",
    "\n",
    "\n",
    "# Checking common column names\n",
    "for i in list(df1.columns):\n",
    "    if i in list(df2.columns):\n",
    "        print (i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ca760056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS\n",
      "EDUCATION\n",
      "GENDER\n",
      "last_prod_enq2\n",
      "first_prod_enq2\n",
      "Approved_Flag\n"
     ]
    }
   ],
   "source": [
    "# Merge the two dataframes, inner join so that no nulls are present\n",
    "df = pd. merge(df1, df2, how ='inner', left_on = ['PROSPECTID'], right_on = ['PROSPECTID'] )\n",
    "\n",
    "# check how many columns are categorical\n",
    "for i in df.columns:\n",
    "    if df[i].dtype == 'object':\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c65c4d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MARITALSTATUS --- 3.578180861038862e-233\n",
      "EDUCATION --- 2.6942265249737532e-30\n",
      "GENDER --- 1.907936100186563e-05\n",
      "last_prod_enq2 --- 0.0\n",
      "first_prod_enq2 --- 7.84997610555419e-287\n"
     ]
    }
   ],
   "source": [
    "# Chi-square test\n",
    "for i in ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', 'first_prod_enq2']:\n",
    "    chi2, pval, _, _ = chi2_contingency(pd.crosstab(df[i], df['Approved_Flag']))\n",
    "    print(i, '---', pval)\n",
    "\n",
    "\n",
    "# Since all the categorical features have pval <=0.05, we will accept all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a652212",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VIF for numerical columns\n",
    "numeric_columns = []\n",
    "for i in df.columns:\n",
    "    if df[i].dtype != 'object' and i not in ['PROSPECTID','Approved_Flag']:\n",
    "        numeric_columns.append(i)\n",
    "\n",
    "#VIF CHECK\n",
    "\n",
    "vif_data = df[numeric_columns]\n",
    "total_columns = vif_data.shape[1]\n",
    "columns_to_be_kept = []\n",
    "column_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b11d46ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manelmahroug/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manelmahroug/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 --- inf\n",
      "0 --- 11.320180023967982\n",
      "0 --- 8.36369803500036\n",
      "0 --- 6.5206478777909425\n",
      "0 --- 5.14950161821261\n",
      "1 --- 2.611111040579735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manelmahroug/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 --- inf\n",
      "2 --- 1788.7926256209232\n",
      "2 --- 8.601028256477212\n",
      "2 --- 3.832800792153082\n",
      "3 --- 6.0996533816466405\n",
      "3 --- 5.581352009642814\n",
      "4 --- 1.9855843530987702\n",
      "5 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manelmahroug/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 --- 4.809538302819332\n",
      "6 --- 23.270628983464636\n",
      "6 --- 30.595522588099946\n",
      "6 --- 4.384346405965575\n",
      "7 --- 3.0646584155234122\n",
      "8 --- 2.898639771299225\n",
      "9 --- 4.377876915347337\n",
      "10 --- 2.2078535836958486\n",
      "11 --- 4.916914200506877\n",
      "12 --- 5.214702030064743\n",
      "13 --- 3.3861625024231516\n",
      "14 --- 7.84058330947899\n",
      "14 --- 5.255034641721459\n",
      "15 --- inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manelmahroug/anaconda3/lib/python3.10/site-packages/statsmodels/stats/outliers_influence.py:195: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  vif = 1. / (1. - r_squared_i)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 --- 7.380634506427207\n",
      "15 --- 1.421005001517572\n",
      "16 --- 8.083255010190301\n",
      "16 --- 1.6241227524040012\n",
      "17 --- 7.257811920140015\n",
      "17 --- 15.596243832683006\n",
      "17 --- 1.825857047132431\n",
      "18 --- 1.5080839450032724\n",
      "19 --- 2.1720888348245815\n",
      "20 --- 2.6233975535272367\n",
      "21 --- 2.2959970812106216\n",
      "22 --- 7.360578319196457\n",
      "22 --- 2.1602387773102514\n",
      "23 --- 2.8686288267891493\n",
      "24 --- 6.458218003637239\n",
      "24 --- 2.847411886563821\n",
      "25 --- 4.753198156284062\n",
      "26 --- 16.22735475594819\n",
      "26 --- 6.424377256363831\n",
      "26 --- 8.887080381808696\n",
      "26 --- 2.3804746142952564\n",
      "27 --- 8.609513476514524\n",
      "27 --- 13.067550935476769\n",
      "27 --- 3.500040056654664\n",
      "28 --- 1.908795587481377\n",
      "29 --- 17.006562234161628\n",
      "29 --- 10.73048515371916\n",
      "29 --- 2.3538497522950457\n",
      "30 --- 22.104855915136543\n",
      "30 --- 2.797163963851296\n",
      "31 --- 3.4241712032177065\n",
      "32 --- 10.17502145445105\n",
      "32 --- 6.408710354561287\n",
      "32 --- 1.0011511962625617\n",
      "33 --- 3.06919730539727\n",
      "34 --- 2.8091261600643707\n",
      "35 --- 20.249538381980678\n",
      "35 --- 15.864576541593886\n",
      "35 --- 1.8331649740532123\n",
      "36 --- 1.5680839909542181\n",
      "37 --- 1.930757235381163\n",
      "38 --- 4.33126505664525\n",
      "39 --- 9.390334396150184\n"
     ]
    }
   ],
   "source": [
    "for i in range (0,total_columns):\n",
    "    \n",
    "    vif_value = variance_inflation_factor(vif_data, column_index)\n",
    "    print (column_index,'---',vif_value)\n",
    "    \n",
    "    \n",
    "    if vif_value <= 6:\n",
    "        columns_to_be_kept.append(numeric_columns[i])\n",
    "        column_index = column_index+1\n",
    "    \n",
    "    else:\n",
    "        vif_data = vif_data.drop([ numeric_columns[i] ] , axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abf3624b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check Anova for columns_to_be_kept \n",
    "\n",
    "from scipy.stats import f_oneway\n",
    "\n",
    "columns_to_be_kept_numerical = []\n",
    "\n",
    "for i in columns_to_be_kept:\n",
    "    a = list(df[i])  \n",
    "    b = list(df['Approved_Flag'])  \n",
    "    \n",
    "    group_P1 = [value for value, group in zip(a, b) if group == 'P1']\n",
    "    group_P2 = [value for value, group in zip(a, b) if group == 'P2']\n",
    "    group_P3 = [value for value, group in zip(a, b) if group == 'P3']\n",
    "    group_P4 = [value for value, group in zip(a, b) if group == 'P4']\n",
    "\n",
    "\n",
    "    f_statistic, p_value = f_oneway(group_P1, group_P2, group_P3, group_P4)\n",
    "\n",
    "    if p_value <= 0.05:\n",
    "        columns_to_be_kept_numerical.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3d7ef4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42064 entries, 0 to 42063\n",
      "Data columns (total 43 columns):\n",
      " #   Column                     Non-Null Count  Dtype  \n",
      "---  ------                     --------------  -----  \n",
      " 0   pct_tl_open_L6M            42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M          42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M         42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M         42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt            42064 non-null  int64  \n",
      " 5   CC_TL                      42064 non-null  int64  \n",
      " 6   Home_TL                    42064 non-null  int64  \n",
      " 7   PL_TL                      42064 non-null  int64  \n",
      " 8   Secured_TL                 42064 non-null  int64  \n",
      " 9   Unsecured_TL               42064 non-null  int64  \n",
      " 10  Other_TL                   42064 non-null  int64  \n",
      " 11  Age_Oldest_TL              42064 non-null  int64  \n",
      " 12  Age_Newest_TL              42064 non-null  int64  \n",
      " 13  time_since_recent_payment  42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq  42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts          42064 non-null  int64  \n",
      " 16  num_times_60p_dpd          42064 non-null  int64  \n",
      " 17  num_std_12mts              42064 non-null  int64  \n",
      " 18  num_sub                    42064 non-null  int64  \n",
      " 19  num_sub_6mts               42064 non-null  int64  \n",
      " 20  num_sub_12mts              42064 non-null  int64  \n",
      " 21  num_dbt                    42064 non-null  int64  \n",
      " 22  num_dbt_12mts              42064 non-null  int64  \n",
      " 23  num_lss                    42064 non-null  int64  \n",
      " 24  recent_level_of_deliq      42064 non-null  int64  \n",
      " 25  CC_enq_L12m                42064 non-null  int64  \n",
      " 26  PL_enq_L12m                42064 non-null  int64  \n",
      " 27  time_since_recent_enq      42064 non-null  int64  \n",
      " 28  enq_L3m                    42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME           42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr        42064 non-null  int64  \n",
      " 31  CC_Flag                    42064 non-null  int64  \n",
      " 32  PL_Flag                    42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever     42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever     42064 non-null  float64\n",
      " 35  HL_Flag                    42064 non-null  int64  \n",
      " 36  GL_Flag                    42064 non-null  int64  \n",
      " 37  MARITALSTATUS              42064 non-null  object \n",
      " 38  EDUCATION                  42064 non-null  int64  \n",
      " 39  GENDER                     42064 non-null  object \n",
      " 40  last_prod_enq2             42064 non-null  object \n",
      " 41  first_prod_enq2            42064 non-null  object \n",
      " 42  Approved_Flag              42064 non-null  object \n",
      "dtypes: float64(5), int64(33), object(5)\n",
      "memory usage: 14.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# feature selection is done for cat and num features\n",
    "\n",
    "# listing all the final features\n",
    "features = columns_to_be_kept_numerical + ['MARITALSTATUS', 'EDUCATION', 'GENDER', 'last_prod_enq2', \\\n",
    "                                           'first_prod_enq2']\n",
    "df = df[features + ['Approved_Flag']]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Label encoding for the categorical features\n",
    "['MARITALSTATUS', 'EDUCATION', 'GENDER' , 'last_prod_enq2' ,'first_prod_enq2']\n",
    "\n",
    "\n",
    "\n",
    "df['MARITALSTATUS'].unique()    \n",
    "df['EDUCATION'].unique()\n",
    "df['GENDER'].unique()\n",
    "df['last_prod_enq2'].unique()\n",
    "df['first_prod_enq2'].unique()\n",
    "\n",
    "\n",
    "\n",
    "# Ordinal feature -- EDUCATION\n",
    "# SSC            : 1\n",
    "# 12TH           : 2\n",
    "# GRADUATE       : 3\n",
    "# UNDER GRADUATE : 3\n",
    "# POST-GRADUATE  : 4\n",
    "# OTHERS         : 1\n",
    "# PROFESSIONAL   : 3\n",
    "\n",
    "\n",
    "# Others has to be verified by the business end user \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df.loc[df['EDUCATION'] == 'SSC',['EDUCATION']]              = 1\n",
    "df.loc[df['EDUCATION'] == '12TH',['EDUCATION']]             = 2\n",
    "df.loc[df['EDUCATION'] == 'GRADUATE',['EDUCATION']]         = 3\n",
    "df.loc[df['EDUCATION'] == 'UNDER GRADUATE',['EDUCATION']]   = 3\n",
    "df.loc[df['EDUCATION'] == 'POST-GRADUATE',['EDUCATION']]    = 4\n",
    "df.loc[df['EDUCATION'] == 'OTHERS',['EDUCATION']]           = 1\n",
    "df.loc[df['EDUCATION'] == 'PROFESSIONAL',['EDUCATION']]     = 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['EDUCATION'].value_counts()\n",
    "df['EDUCATION'] = df['EDUCATION'].astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc6c9115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 42064 entries, 0 to 42063\n",
      "Data columns (total 55 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   pct_tl_open_L6M               42064 non-null  float64\n",
      " 1   pct_tl_closed_L6M             42064 non-null  float64\n",
      " 2   Tot_TL_closed_L12M            42064 non-null  int64  \n",
      " 3   pct_tl_closed_L12M            42064 non-null  float64\n",
      " 4   Tot_Missed_Pmnt               42064 non-null  int64  \n",
      " 5   CC_TL                         42064 non-null  int64  \n",
      " 6   Home_TL                       42064 non-null  int64  \n",
      " 7   PL_TL                         42064 non-null  int64  \n",
      " 8   Secured_TL                    42064 non-null  int64  \n",
      " 9   Unsecured_TL                  42064 non-null  int64  \n",
      " 10  Other_TL                      42064 non-null  int64  \n",
      " 11  Age_Oldest_TL                 42064 non-null  int64  \n",
      " 12  Age_Newest_TL                 42064 non-null  int64  \n",
      " 13  time_since_recent_payment     42064 non-null  int64  \n",
      " 14  max_recent_level_of_deliq     42064 non-null  int64  \n",
      " 15  num_deliq_6_12mts             42064 non-null  int64  \n",
      " 16  num_times_60p_dpd             42064 non-null  int64  \n",
      " 17  num_std_12mts                 42064 non-null  int64  \n",
      " 18  num_sub                       42064 non-null  int64  \n",
      " 19  num_sub_6mts                  42064 non-null  int64  \n",
      " 20  num_sub_12mts                 42064 non-null  int64  \n",
      " 21  num_dbt                       42064 non-null  int64  \n",
      " 22  num_dbt_12mts                 42064 non-null  int64  \n",
      " 23  num_lss                       42064 non-null  int64  \n",
      " 24  recent_level_of_deliq         42064 non-null  int64  \n",
      " 25  CC_enq_L12m                   42064 non-null  int64  \n",
      " 26  PL_enq_L12m                   42064 non-null  int64  \n",
      " 27  time_since_recent_enq         42064 non-null  int64  \n",
      " 28  enq_L3m                       42064 non-null  int64  \n",
      " 29  NETMONTHLYINCOME              42064 non-null  int64  \n",
      " 30  Time_With_Curr_Empr           42064 non-null  int64  \n",
      " 31  CC_Flag                       42064 non-null  int64  \n",
      " 32  PL_Flag                       42064 non-null  int64  \n",
      " 33  pct_PL_enq_L6m_of_ever        42064 non-null  float64\n",
      " 34  pct_CC_enq_L6m_of_ever        42064 non-null  float64\n",
      " 35  HL_Flag                       42064 non-null  int64  \n",
      " 36  GL_Flag                       42064 non-null  int64  \n",
      " 37  EDUCATION                     42064 non-null  int64  \n",
      " 38  Approved_Flag                 42064 non-null  object \n",
      " 39  MARITALSTATUS_Married         42064 non-null  uint8  \n",
      " 40  MARITALSTATUS_Single          42064 non-null  uint8  \n",
      " 41  GENDER_F                      42064 non-null  uint8  \n",
      " 42  GENDER_M                      42064 non-null  uint8  \n",
      " 43  last_prod_enq2_AL             42064 non-null  uint8  \n",
      " 44  last_prod_enq2_CC             42064 non-null  uint8  \n",
      " 45  last_prod_enq2_ConsumerLoan   42064 non-null  uint8  \n",
      " 46  last_prod_enq2_HL             42064 non-null  uint8  \n",
      " 47  last_prod_enq2_PL             42064 non-null  uint8  \n",
      " 48  last_prod_enq2_others         42064 non-null  uint8  \n",
      " 49  first_prod_enq2_AL            42064 non-null  uint8  \n",
      " 50  first_prod_enq2_CC            42064 non-null  uint8  \n",
      " 51  first_prod_enq2_ConsumerLoan  42064 non-null  uint8  \n",
      " 52  first_prod_enq2_HL            42064 non-null  uint8  \n",
      " 53  first_prod_enq2_PL            42064 non-null  uint8  \n",
      " 54  first_prod_enq2_others        42064 non-null  uint8  \n",
      "dtypes: float64(5), int64(33), object(1), uint8(16)\n",
      "memory usage: 13.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df_encoded = pd.get_dummies(df, columns=['MARITALSTATUS','GENDER', 'last_prod_enq2' ,'first_prod_enq2'])\n",
    "\n",
    "df_encoded.info()\n",
    "k = df_encoded.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6536c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.7657197194817544\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.8329466357308585\n",
      "Recall: 0.7080867850098619\n",
      "F1 Score: 0.7654584221748401\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.7975805077525984\n",
      "Recall: 0.9278493557978196\n",
      "F1 Score: 0.8577973245372915\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.44976816074188564\n",
      "Recall: 0.21962264150943397\n",
      "F1 Score: 0.29513184584178503\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7265700483091787\n",
      "Recall: 0.7308066083576288\n",
      "F1 Score: 0.7286821705426356\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Machine Learing model fitting\n",
    "# Data processing\n",
    "\n",
    "# 1. Random Forest\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "rf_classifier = RandomForestClassifier(n_estimators = 200, random_state=42)\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print ()\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a120093c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: scipy in /Users/manelmahroug/anaconda3/lib/python3.10/site-packages (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/manelmahroug/anaconda3/lib/python3.10/site-packages (from xgboost) (1.23.5)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86379af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.78\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.823906083244397\n",
      "Recall: 0.7613412228796844\n",
      "F1 Score: 0.7913890312660173\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8255418233924413\n",
      "Recall: 0.913577799801784\n",
      "F1 Score: 0.8673315769665036\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4756380510440835\n",
      "Recall: 0.30943396226415093\n",
      "F1 Score: 0.3749428440786465\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7342386032977691\n",
      "Recall: 0.7356656948493683\n",
      "F1 Score: 0.7349514563106796\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. xgboost\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b7db422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy: 0.71\n",
      "\n",
      "Class p1:\n",
      "Precision: 0.7277179236043095\n",
      "Recall: 0.7327416173570019\n",
      "F1 Score: 0.7302211302211303\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8102005061319837\n",
      "Recall: 0.8249752229930625\n",
      "F1 Score: 0.8175211156943627\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.34651898734177217\n",
      "Recall: 0.3305660377358491\n",
      "F1 Score: 0.3383545770567787\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.6528758829465187\n",
      "Recall: 0.6287657920310982\n",
      "F1 Score: 0.6405940594059405\n",
      "\n",
      "Accuracy: 0.78\n",
      "Class p1:\n",
      "Precision: 0.823906083244397\n",
      "Recall: 0.7613412228796844\n",
      "F1 Score: 0.7913890312660173\n",
      "\n",
      "Class p2:\n",
      "Precision: 0.8255418233924413\n",
      "Recall: 0.913577799801784\n",
      "F1 Score: 0.8673315769665036\n",
      "\n",
      "Class p3:\n",
      "Precision: 0.4756380510440835\n",
      "Recall: 0.30943396226415093\n",
      "F1 Score: 0.3749428440786465\n",
      "\n",
      "Class p4:\n",
      "Precision: 0.7342386032977691\n",
      "Recall: 0.7356656948493683\n",
      "F1 Score: 0.7349514563106796\n",
      "\n",
      "Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
      "Test Accuracy: 0.7811719957209081\n"
     ]
    }
   ],
   "source": [
    "# 3. Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "dt_model = DecisionTreeClassifier(max_depth=20, min_samples_split=10)\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred = dt_model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print ()\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print ()\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# xgboost is giving me best results\n",
    "# We will further finetune it\n",
    "\n",
    "\n",
    "# Apply standard scaler \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "columns_to_be_scaled = ['Age_Oldest_TL','Age_Newest_TL','time_since_recent_payment',\n",
    "'max_recent_level_of_deliq','recent_level_of_deliq',\n",
    "'time_since_recent_enq','NETMONTHLYINCOME','Time_With_Curr_Empr']\n",
    "\n",
    "for i in columns_to_be_scaled:\n",
    "    column_data = df_encoded[i].values.reshape(-1, 1)\n",
    "    scaler = StandardScaler()\n",
    "    scaled_column = scaler.fit_transform(column_data)\n",
    "    df_encoded[i] = scaled_column\n",
    "\n",
    "\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "xgb_classifier = xgb.XGBClassifier(objective='multi:softmax',  num_class=4)\n",
    "\n",
    "\n",
    "\n",
    "y = df_encoded['Approved_Flag']\n",
    "x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "xgb_classifier.fit(x_train, y_train)\n",
    "y_pred = xgb_classifier.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_test, y_pred)\n",
    "\n",
    "for i, v in enumerate(['p1', 'p2', 'p3', 'p4']):\n",
    "    print(f\"Class {v}:\")\n",
    "    print(f\"Precision: {precision[i]}\")\n",
    "    print(f\"Recall: {recall[i]}\")\n",
    "    print(f\"F1 Score: {f1_score[i]}\")\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    \n",
    "# No improvement in metrices\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Hyperparameter tuning in xgboost\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the XGBClassifier with the initial set of hyperparameters\n",
    "xgb_model = xgb.XGBClassifier(objective='multi:softmax', num_class=4)\n",
    "\n",
    "# Define the parameter grid for hyperparameter tuning\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(x_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best Hyperparameters:\", grid_search.best_params_)\n",
    "\n",
    "# Evaluate the model with the best hyperparameters on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "accuracy = best_model.score(x_test, y_test)\n",
    "print(\"Test Accuracy:\", accuracy)\n",
    "\n",
    "# Best Hyperparameters: {'learning_rate': 0.2, 'max_depth': 3, 'n_estimators': 200}\n",
    "\n",
    "\n",
    "# Based on risk appetite of the bank, you will suggest P1,P2,P3,P4 to the business end user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cedcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Hyperparameter tuning for xgboost (Used in the session)\n",
    "\n",
    "# # Define the hyperparameter grid\n",
    "# param_grid = {\n",
    "#   'colsample_bytree': [0.1, 0.3, 0.5, 0.7, 0.9],\n",
    "#   'learning_rate'   : [0.001, 0.01, 0.1, 1],\n",
    "#   'max_depth'       : [3, 5, 8, 10],\n",
    "#   'alpha'           : [1, 10, 100],\n",
    "#   'n_estimators'    : [10,50,100]\n",
    "# }\n",
    "\n",
    "# index = 0\n",
    "\n",
    "# answers_grid = {\n",
    "#     'combination'       :[],\n",
    "#     'train_Accuracy'    :[],\n",
    "#     'test_Accuracy'     :[],\n",
    "#     'colsample_bytree'  :[],\n",
    "#     'learning_rate'     :[],\n",
    "#     'max_depth'         :[],\n",
    "#     'alpha'             :[],\n",
    "#     'n_estimators'      :[]\n",
    "\n",
    "#     }\n",
    "\n",
    "\n",
    "# # Loop through each combination of hyperparameters\n",
    "# for colsample_bytree in param_grid['colsample_bytree']:\n",
    "#   for learning_rate in param_grid['learning_rate']:\n",
    "#     for max_depth in param_grid['max_depth']:\n",
    "#       for alpha in param_grid['alpha']:\n",
    "#           for n_estimators in param_grid['n_estimators']:\n",
    "             \n",
    "#               index = index + 1\n",
    "             \n",
    "#               # Define and train the XGBoost model\n",
    "#               model = xgb.XGBClassifier(objective='multi:softmax',  \n",
    "#                                        num_class=4,\n",
    "#                                        colsample_bytree = colsample_bytree,\n",
    "#                                        learning_rate = learning_rate,\n",
    "#                                        max_depth = max_depth,\n",
    "#                                        alpha = alpha,\n",
    "#                                        n_estimators = n_estimators)\n",
    "               \n",
    "       \n",
    "                     \n",
    "#               y = df_encoded['Approved_Flag']\n",
    "#               x = df_encoded. drop ( ['Approved_Flag'], axis = 1 )\n",
    "\n",
    "#               label_encoder = LabelEncoder()\n",
    "#               y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "#               x_train, x_test, y_train, y_test = train_test_split(x, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "#               model.fit(x_train, y_train)\n",
    "  \n",
    "\n",
    "       \n",
    "#               # Predict on training and testing sets\n",
    "#               y_pred_train = model.predict(x_train)\n",
    "#               y_pred_test = model.predict(x_test)\n",
    "       \n",
    "       \n",
    "#               # Calculate train and test results\n",
    "              \n",
    "#               train_accuracy =  accuracy_score (y_train, y_pred_train)\n",
    "#               test_accuracy  =  accuracy_score (y_test , y_pred_test)\n",
    "\n",
    "#               Include into the lists\n",
    "#               answers_grid ['combination']   .append(index)\n",
    "#               answers_grid ['train_Accuracy']    .append(train_accuracy)\n",
    "#               answers_grid ['test_Accuracy']     .append(test_accuracy)\n",
    "#               answers_grid ['colsample_bytree']   .append(colsample_bytree)\n",
    "#               answers_grid ['learning_rate']      .append(learning_rate)\n",
    "#               answers_grid ['max_depth']          .append(max_depth)\n",
    "#               answers_grid ['alpha']              .append(alpha)\n",
    "#               answers_grid ['n_estimators']       .append(n_estimators)\n",
    "       \n",
    "       \n",
    "#               # Print results for this combination\n",
    "#               print(f\"Combination {index}\")\n",
    "#               print(f\"colsample_bytree: {colsample_bytree}, learning_rate: {learning_rate}, max_depth: {max_depth}, alpha: {alpha}, n_estimators: {n_estimators}\")\n",
    "#               print(f\"Train Accuracy: {train_accuracy:.2f}\")\n",
    "#               print(f\"Test Accuracy : {test_accuracy :.2f}\")\n",
    "#               print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
